{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(os.getcwd(),'dataset')\n",
    "classes = os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio_file(file_path):\n",
    "    feature = []\n",
    "    audio_data, sr = librosa.load(file_path)\n",
    "\n",
    "    # Extract audio features and append to feature list\n",
    "    rms = librosa.feature.rms(y=audio_data)\n",
    "    rms_mean = np.mean(rms, axis=1)\n",
    "    rms_median = np.median(rms, axis=1)\n",
    "    feature.extend([rms_mean[0], rms_median[0]])\n",
    "\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=audio_data, sr=sr)\n",
    "    spec_bw_mean = np.mean(spec_bw,axis=1)\n",
    "    spec_bw_median = np.median(spec_bw,axis=1)\n",
    "    feature.extend([spec_bw_mean[0],spec_bw_median[0]])\n",
    "\n",
    "    S = np.abs(librosa.stft(y=audio_data))\n",
    "    contrast = librosa.feature.spectral_contrast(S=S, sr=sr)\n",
    "    contrast_row_mean = np.mean(np.mean(contrast,axis=1))\n",
    "    contrast_col_mean = np.mean(np.mean(contrast,axis=0))\n",
    "    contrast_row_median = np.median(np.median(contrast,axis=1))\n",
    "    contrast_col_median = np.median(np.median(contrast,axis=0))\n",
    "    feature.extend([contrast_row_mean, contrast_col_mean, contrast_row_median, contrast_col_median])\n",
    "\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=audio_data, sr=sr)\n",
    "    chroma_cq = librosa.feature.chroma_cqt(y=audio_data, sr=sr)\n",
    "    chroma_cens_row_mean = np.mean(np.mean(chroma_cens,axis=1))\n",
    "    chroma_cens_col_mean = np.mean(np.mean(chroma_cens,axis=0))\n",
    "    chroma_cens_row_median = np.median(np.median(chroma_cq,axis=1))\n",
    "    chroma_cens_col_median = np.median(np.median(chroma_cq,axis=0))\n",
    "    chroma_cq_row_mean = np.mean(np.mean(chroma_cens,axis=1))\n",
    "    chroma_cq_col_mean = np.mean(np.mean(chroma_cens,axis=0))\n",
    "    chroma_cq_row_median = np.median(np.median(chroma_cq,axis=1))\n",
    "    chroma_cq_col_median = np.median(np.median(chroma_cq,axis=0))\n",
    "    feature.extend([chroma_cens_row_mean, chroma_cens_col_mean, chroma_cens_row_median, chroma_cens_col_median, chroma_cq_row_mean, chroma_cq_col_mean, chroma_cq_row_median, chroma_cq_col_median])\n",
    "\n",
    "    cent = librosa.feature.spectral_centroid(y=audio_data, sr=sr)\n",
    "    cent_mean = np.mean(cent,axis=1)\n",
    "    cent_median = np.median(cent,axis=1)\n",
    "    feature.extend([cent_mean[0],cent_median[0]])\n",
    "\n",
    "    flatness = librosa.feature.spectral_flatness(y=audio_data)\n",
    "    flatness_mean = np.mean(flatness,axis=1)\n",
    "    flatness_median = np.median(flatness,axis=1)\n",
    "    feature.extend([flatness_mean[0],flatness_median[0]])\n",
    "\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=audio_data, sr=sr)\n",
    "    rolloff_mean = np.mean(rolloff,axis=1)\n",
    "    rolloff_median = np.median(rolloff,axis=1)\n",
    "    feature.extend([rolloff_mean[0],rolloff_median[0]])\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=audio_data,sr=sr)\n",
    "    row_mean = np.mean(np.mean(mfcc,axis=1))\n",
    "    col_mean = np.mean(np.mean(mfcc,axis=0))\n",
    "    row_median = np.median(np.median(mfcc,axis=1))\n",
    "    col_median = np.median(np.median(mfcc,axis=0))\n",
    "    feature.extend([row_mean, col_mean, row_median, col_median])\n",
    "\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=audio_data)\n",
    "    zcr_mean = np.mean(zcr,axis=1)\n",
    "    zcr_median = np.median(zcr,axis=1)\n",
    "    feature.extend([zcr_mean[0],zcr_median[0]])\n",
    "\n",
    "    magnitude, phase = librosa.magphase(librosa.stft(y=audio_data))\n",
    "    sro = librosa.feature.spectral_rolloff(S=magnitude,sr=sr)\n",
    "    sro_mean = np.mean(sro,axis=1)\n",
    "    sro_median = np.median(sro,axis=1)\n",
    "    feature.extend([sro_mean[0],sro_median[0]])\n",
    "\n",
    "    pitches,magnitudes = librosa.core.piptrack(y=audio_data,sr=sr)\n",
    "    pitches_row_mean = np.mean(np.mean(pitches,axis=1))\n",
    "    pitches_col_mean = np.mean(np.mean(pitches,axis=0))\n",
    "    pitches_row_median = np.median(np.median(pitches,axis=1))\n",
    "    pitches_col_median = np.median(np.median(pitches,axis=0))\n",
    "    magnitudes_row_mean = np.mean(np.mean(magnitudes,axis=1))\n",
    "    magnitudes_col_mean = np.mean(np.mean(magnitudes,axis=0))\n",
    "    magnitudes_row_median = np.median(np.median(magnitudes,axis=1))\n",
    "    magnitudes_col_median = np.median(np.median(magnitudes,axis=0))\n",
    "    feature.extend([pitches_row_mean, pitches_col_mean, pitches_row_median, pitches_col_median, magnitudes_row_mean, magnitudes_col_mean, magnitudes_row_median, magnitudes_col_median])\n",
    "\n",
    "    c_stft = librosa.feature.chroma_stft(y=audio_data,sr=sr)\n",
    "    c_stft_row_mean = np.mean(np.mean(c_stft,axis=1))\n",
    "    c_stft_col_mean = np.mean(np.mean(c_stft,axis=0))\n",
    "    c_stft_row_median = np.median(np.median(c_stft,axis=1))\n",
    "    c_stft_col_median = np.median(np.median(c_stft,axis=0))\n",
    "    feature.extend([c_stft_row_mean,c_stft_col_mean,c_stft_row_median,c_stft_col_median])\n",
    "\n",
    "    y = librosa.effects.harmonic(audio_data)\n",
    "    tonnetz = librosa.feature.tonnetz(y=audio_data, sr=sr)\n",
    "    tonnetz_row_mean = np.mean(np.mean(tonnetz,axis=1))\n",
    "    tonnetz_col_mean = np.mean(np.mean(tonnetz,axis=0))\n",
    "    tonnetz_row_median = np.median(np.median(tonnetz,axis=1))\n",
    "    tonnetz_col_median = np.median(np.median(tonnetz,axis=0))\n",
    "    feature.extend([tonnetz_row_mean,tonnetz_col_mean,tonnetz_row_median,tonnetz_col_median])\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversing through Datset and Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\audio.py:175: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=800\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\audio.py:175: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=662\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=855\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=827\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=634\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=607\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=552\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=772\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=745\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=717\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=910\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=882\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=992\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=496\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=441\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=414\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=937\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=469\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=853\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=427\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=956\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=478\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=779\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=390\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=515\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=588\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=574\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=522\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=544\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=846\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=743\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=669\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=581\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=757\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=691\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=625\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=655\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=765\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=530\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=647\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=1015\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=508\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=566\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=610\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=537\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=596\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=941\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=471\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=868\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=434\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=912\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=603\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=897\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=449\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=383\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=721\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=735\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=809\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=993\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=677\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=970\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=485\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=632\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=559\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=985\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=493\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=618\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=579\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=524\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=794\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=802\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=816\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=405\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=875\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=640\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=689\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=1016\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=1000\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=500\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=831\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=1020\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=684\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=728\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=397\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=838\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=456\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=934\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=926\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=463\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=346\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=750\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=890\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=419\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=949\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=963\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=978\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=860\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=965\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=971\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=787\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=824\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=1022\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=375\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=713\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=823\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=412\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=309\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=919\n",
      "  warnings.warn(\n",
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=1024 is too large for input signal of length=904\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(os.getcwd(),'dataset')\n",
    "classes = os.listdir(dataset_path)\n",
    "\n",
    "# Open the CSV file for writing\n",
    "with open('features.csv','a',newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Loop through each class\n",
    "    for clas in classes:\n",
    "        audio_files = os.path.join(dataset_path, clas)\n",
    "\n",
    "        # Loop through each audio file in the class\n",
    "        for file in os.listdir(audio_files):\n",
    "            file_path = os.path.join(dataset_path, clas, file)\n",
    "\n",
    "            # Call the preprocessing function\n",
    "            feature = preprocess_audio_file(file_path)\n",
    "\n",
    "            # Write the feature row to the CSV file\n",
    "            feature.append(clas)\n",
    "            writer.writerow(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Features.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./features.csv')\n",
    "\n",
    "X = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting Dataset into Training and Testing Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Data to PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Datasets and Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleANN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising Input Size, Hidden Size, Number Of Classes, Model, Criterion and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X.shape[1]\n",
    "hidden_size = 64\n",
    "num_classes = len(np.unique(y))\n",
    "model = SimpleANN(input_size=input_size, hidden_size=hidden_size, num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop, Validation Loop, Calculating and Printing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 Training Loss: 0.9421, Training Accuracy: 71.9643%, Validation Loss: 3.2016, Validation Accuracy: 21.7857%\n",
      "Epoch 2/500 Training Loss: 0.9360, Training Accuracy: 73.1250%, Validation Loss: 3.2142, Validation Accuracy: 22.5000%\n",
      "Epoch 3/500 Training Loss: 0.9294, Training Accuracy: 73.9286%, Validation Loss: 3.2386, Validation Accuracy: 21.4286%\n",
      "Epoch 4/500 Training Loss: 0.9253, Training Accuracy: 73.6607%, Validation Loss: 3.2085, Validation Accuracy: 22.1429%\n",
      "Epoch 5/500 Training Loss: 0.9240, Training Accuracy: 73.3036%, Validation Loss: 3.2239, Validation Accuracy: 21.7857%\n",
      "Epoch 6/500 Training Loss: 0.9182, Training Accuracy: 74.3750%, Validation Loss: 3.2311, Validation Accuracy: 21.7857%\n",
      "Epoch 7/500 Training Loss: 0.9195, Training Accuracy: 74.1071%, Validation Loss: 3.2316, Validation Accuracy: 21.7857%\n",
      "Epoch 8/500 Training Loss: 0.9173, Training Accuracy: 75.0000%, Validation Loss: 3.2413, Validation Accuracy: 21.7857%\n",
      "Epoch 9/500 Training Loss: 0.9165, Training Accuracy: 74.6429%, Validation Loss: 3.2435, Validation Accuracy: 21.4286%\n",
      "Epoch 10/500 Training Loss: 0.9115, Training Accuracy: 75.0893%, Validation Loss: 3.2726, Validation Accuracy: 20.3571%\n",
      "Epoch 11/500 Training Loss: 0.9090, Training Accuracy: 74.6429%, Validation Loss: 3.2440, Validation Accuracy: 22.1429%\n",
      "Epoch 12/500 Training Loss: 0.9090, Training Accuracy: 74.6429%, Validation Loss: 3.2675, Validation Accuracy: 21.0714%\n",
      "Epoch 13/500 Training Loss: 0.9021, Training Accuracy: 75.2679%, Validation Loss: 3.2798, Validation Accuracy: 21.4286%\n",
      "Epoch 14/500 Training Loss: 0.9010, Training Accuracy: 74.9107%, Validation Loss: 3.2709, Validation Accuracy: 20.7143%\n",
      "Epoch 15/500 Training Loss: 0.8961, Training Accuracy: 75.7143%, Validation Loss: 3.2762, Validation Accuracy: 22.5000%\n",
      "Epoch 16/500 Training Loss: 0.8988, Training Accuracy: 74.9107%, Validation Loss: 3.2809, Validation Accuracy: 21.0714%\n",
      "Epoch 17/500 Training Loss: 0.8942, Training Accuracy: 76.0714%, Validation Loss: 3.3017, Validation Accuracy: 22.1429%\n",
      "Epoch 18/500 Training Loss: 0.8942, Training Accuracy: 74.3750%, Validation Loss: 3.2666, Validation Accuracy: 22.8571%\n",
      "Epoch 19/500 Training Loss: 0.8839, Training Accuracy: 75.7143%, Validation Loss: 3.2908, Validation Accuracy: 23.2143%\n",
      "Epoch 20/500 Training Loss: 0.8831, Training Accuracy: 75.2679%, Validation Loss: 3.2864, Validation Accuracy: 21.4286%\n",
      "Epoch 21/500 Training Loss: 0.8829, Training Accuracy: 75.1786%, Validation Loss: 3.3045, Validation Accuracy: 21.4286%\n",
      "Epoch 22/500 Training Loss: 0.8838, Training Accuracy: 75.1786%, Validation Loss: 3.2954, Validation Accuracy: 22.5000%\n",
      "Epoch 23/500 Training Loss: 0.8766, Training Accuracy: 76.2500%, Validation Loss: 3.3068, Validation Accuracy: 22.5000%\n",
      "Epoch 24/500 Training Loss: 0.8749, Training Accuracy: 75.8036%, Validation Loss: 3.3074, Validation Accuracy: 21.4286%\n",
      "Epoch 25/500 Training Loss: 0.8704, Training Accuracy: 75.7143%, Validation Loss: 3.3154, Validation Accuracy: 23.5714%\n",
      "Epoch 26/500 Training Loss: 0.8723, Training Accuracy: 76.1607%, Validation Loss: 3.3226, Validation Accuracy: 21.4286%\n",
      "Epoch 27/500 Training Loss: 0.8683, Training Accuracy: 76.4286%, Validation Loss: 3.3241, Validation Accuracy: 22.5000%\n",
      "Epoch 28/500 Training Loss: 0.8617, Training Accuracy: 76.6071%, Validation Loss: 3.3121, Validation Accuracy: 22.1429%\n",
      "Epoch 29/500 Training Loss: 0.8567, Training Accuracy: 75.9821%, Validation Loss: 3.3360, Validation Accuracy: 21.7857%\n",
      "Epoch 30/500 Training Loss: 0.8594, Training Accuracy: 76.5179%, Validation Loss: 3.3276, Validation Accuracy: 21.4286%\n",
      "Epoch 31/500 Training Loss: 0.8576, Training Accuracy: 76.6964%, Validation Loss: 3.3424, Validation Accuracy: 20.3571%\n",
      "Epoch 32/500 Training Loss: 0.8578, Training Accuracy: 75.7143%, Validation Loss: 3.3383, Validation Accuracy: 21.7857%\n",
      "Epoch 33/500 Training Loss: 0.8553, Training Accuracy: 75.8036%, Validation Loss: 3.3499, Validation Accuracy: 21.4286%\n",
      "Epoch 34/500 Training Loss: 0.8466, Training Accuracy: 77.9464%, Validation Loss: 3.3718, Validation Accuracy: 22.5000%\n",
      "Epoch 35/500 Training Loss: 0.8470, Training Accuracy: 76.6964%, Validation Loss: 3.3604, Validation Accuracy: 22.5000%\n",
      "Epoch 36/500 Training Loss: 0.8441, Training Accuracy: 76.6071%, Validation Loss: 3.3437, Validation Accuracy: 21.4286%\n",
      "Epoch 37/500 Training Loss: 0.8428, Training Accuracy: 77.0536%, Validation Loss: 3.3598, Validation Accuracy: 21.4286%\n",
      "Epoch 38/500 Training Loss: 0.8414, Training Accuracy: 76.4286%, Validation Loss: 3.3537, Validation Accuracy: 22.5000%\n",
      "Epoch 39/500 Training Loss: 0.8367, Training Accuracy: 77.9464%, Validation Loss: 3.3619, Validation Accuracy: 21.0714%\n",
      "Epoch 40/500 Training Loss: 0.8358, Training Accuracy: 77.4107%, Validation Loss: 3.3905, Validation Accuracy: 22.1429%\n",
      "Epoch 41/500 Training Loss: 0.8342, Training Accuracy: 77.5000%, Validation Loss: 3.3826, Validation Accuracy: 22.1429%\n",
      "Epoch 42/500 Training Loss: 0.8308, Training Accuracy: 77.6786%, Validation Loss: 3.4105, Validation Accuracy: 22.5000%\n",
      "Epoch 43/500 Training Loss: 0.8301, Training Accuracy: 77.0536%, Validation Loss: 3.3812, Validation Accuracy: 21.7857%\n",
      "Epoch 44/500 Training Loss: 0.8268, Training Accuracy: 77.4107%, Validation Loss: 3.4012, Validation Accuracy: 21.7857%\n",
      "Epoch 45/500 Training Loss: 0.8250, Training Accuracy: 77.5893%, Validation Loss: 3.4126, Validation Accuracy: 21.0714%\n",
      "Epoch 46/500 Training Loss: 0.8217, Training Accuracy: 78.1250%, Validation Loss: 3.4030, Validation Accuracy: 20.7143%\n",
      "Epoch 47/500 Training Loss: 0.8217, Training Accuracy: 77.3214%, Validation Loss: 3.4232, Validation Accuracy: 21.4286%\n",
      "Epoch 48/500 Training Loss: 0.8170, Training Accuracy: 78.1250%, Validation Loss: 3.4183, Validation Accuracy: 21.7857%\n",
      "Epoch 49/500 Training Loss: 0.8128, Training Accuracy: 78.2143%, Validation Loss: 3.4333, Validation Accuracy: 20.3571%\n",
      "Epoch 50/500 Training Loss: 0.8137, Training Accuracy: 78.0357%, Validation Loss: 3.4280, Validation Accuracy: 22.1429%\n",
      "Epoch 51/500 Training Loss: 0.8106, Training Accuracy: 78.0357%, Validation Loss: 3.4280, Validation Accuracy: 21.7857%\n",
      "Epoch 52/500 Training Loss: 0.8085, Training Accuracy: 78.4821%, Validation Loss: 3.4248, Validation Accuracy: 22.1429%\n",
      "Epoch 53/500 Training Loss: 0.8019, Training Accuracy: 79.0179%, Validation Loss: 3.4713, Validation Accuracy: 21.0714%\n",
      "Epoch 54/500 Training Loss: 0.8054, Training Accuracy: 78.0357%, Validation Loss: 3.4491, Validation Accuracy: 21.4286%\n",
      "Epoch 55/500 Training Loss: 0.8008, Training Accuracy: 78.3929%, Validation Loss: 3.4702, Validation Accuracy: 21.7857%\n",
      "Epoch 56/500 Training Loss: 0.7981, Training Accuracy: 77.7679%, Validation Loss: 3.4608, Validation Accuracy: 21.4286%\n",
      "Epoch 57/500 Training Loss: 0.7981, Training Accuracy: 77.6786%, Validation Loss: 3.4509, Validation Accuracy: 21.4286%\n",
      "Epoch 58/500 Training Loss: 0.7910, Training Accuracy: 78.7500%, Validation Loss: 3.4793, Validation Accuracy: 19.2857%\n",
      "Epoch 59/500 Training Loss: 0.7961, Training Accuracy: 78.6607%, Validation Loss: 3.4495, Validation Accuracy: 21.7857%\n",
      "Epoch 60/500 Training Loss: 0.7921, Training Accuracy: 79.1071%, Validation Loss: 3.4679, Validation Accuracy: 22.8571%\n",
      "Epoch 61/500 Training Loss: 0.7889, Training Accuracy: 78.4821%, Validation Loss: 3.4944, Validation Accuracy: 23.2143%\n",
      "Epoch 62/500 Training Loss: 0.7905, Training Accuracy: 78.6607%, Validation Loss: 3.4762, Validation Accuracy: 21.4286%\n",
      "Epoch 63/500 Training Loss: 0.7827, Training Accuracy: 79.1071%, Validation Loss: 3.4947, Validation Accuracy: 21.0714%\n",
      "Epoch 64/500 Training Loss: 0.7833, Training Accuracy: 78.1250%, Validation Loss: 3.4826, Validation Accuracy: 21.7857%\n",
      "Epoch 65/500 Training Loss: 0.7810, Training Accuracy: 79.5536%, Validation Loss: 3.4919, Validation Accuracy: 21.7857%\n",
      "Epoch 66/500 Training Loss: 0.7786, Training Accuracy: 78.7500%, Validation Loss: 3.4875, Validation Accuracy: 21.4286%\n",
      "Epoch 67/500 Training Loss: 0.7716, Training Accuracy: 79.1964%, Validation Loss: 3.4966, Validation Accuracy: 21.7857%\n",
      "Epoch 68/500 Training Loss: 0.7738, Training Accuracy: 79.2857%, Validation Loss: 3.5082, Validation Accuracy: 21.4286%\n",
      "Epoch 69/500 Training Loss: 0.7706, Training Accuracy: 79.1071%, Validation Loss: 3.5010, Validation Accuracy: 22.8571%\n",
      "Epoch 70/500 Training Loss: 0.7672, Training Accuracy: 79.8214%, Validation Loss: 3.5244, Validation Accuracy: 21.0714%\n",
      "Epoch 71/500 Training Loss: 0.7650, Training Accuracy: 78.8393%, Validation Loss: 3.5196, Validation Accuracy: 22.1429%\n",
      "Epoch 72/500 Training Loss: 0.7696, Training Accuracy: 79.9107%, Validation Loss: 3.5355, Validation Accuracy: 21.0714%\n",
      "Epoch 73/500 Training Loss: 0.7577, Training Accuracy: 80.1786%, Validation Loss: 3.5322, Validation Accuracy: 20.7143%\n",
      "Epoch 74/500 Training Loss: 0.7561, Training Accuracy: 79.4643%, Validation Loss: 3.5431, Validation Accuracy: 22.8571%\n",
      "Epoch 75/500 Training Loss: 0.7592, Training Accuracy: 79.3750%, Validation Loss: 3.5296, Validation Accuracy: 22.1429%\n",
      "Epoch 76/500 Training Loss: 0.7567, Training Accuracy: 80.2679%, Validation Loss: 3.5661, Validation Accuracy: 20.7143%\n",
      "Epoch 77/500 Training Loss: 0.7528, Training Accuracy: 80.0893%, Validation Loss: 3.5551, Validation Accuracy: 21.0714%\n",
      "Epoch 78/500 Training Loss: 0.7503, Training Accuracy: 79.7321%, Validation Loss: 3.5539, Validation Accuracy: 21.4286%\n",
      "Epoch 79/500 Training Loss: 0.7482, Training Accuracy: 80.8929%, Validation Loss: 3.5536, Validation Accuracy: 21.4286%\n",
      "Epoch 80/500 Training Loss: 0.7505, Training Accuracy: 79.2857%, Validation Loss: 3.5601, Validation Accuracy: 21.0714%\n",
      "Epoch 81/500 Training Loss: 0.7417, Training Accuracy: 80.3571%, Validation Loss: 3.5876, Validation Accuracy: 21.4286%\n",
      "Epoch 82/500 Training Loss: 0.7421, Training Accuracy: 79.9107%, Validation Loss: 3.5757, Validation Accuracy: 21.0714%\n",
      "Epoch 83/500 Training Loss: 0.7402, Training Accuracy: 81.0714%, Validation Loss: 3.5888, Validation Accuracy: 21.7857%\n",
      "Epoch 84/500 Training Loss: 0.7398, Training Accuracy: 81.0714%, Validation Loss: 3.6005, Validation Accuracy: 20.7143%\n",
      "Epoch 85/500 Training Loss: 0.7362, Training Accuracy: 81.0714%, Validation Loss: 3.5847, Validation Accuracy: 21.4286%\n",
      "Epoch 86/500 Training Loss: 0.7370, Training Accuracy: 80.5357%, Validation Loss: 3.6026, Validation Accuracy: 22.1429%\n",
      "Epoch 87/500 Training Loss: 0.7355, Training Accuracy: 80.9821%, Validation Loss: 3.6036, Validation Accuracy: 21.7857%\n",
      "Epoch 88/500 Training Loss: 0.7320, Training Accuracy: 81.4286%, Validation Loss: 3.6076, Validation Accuracy: 22.5000%\n",
      "Epoch 89/500 Training Loss: 0.7293, Training Accuracy: 80.5357%, Validation Loss: 3.6037, Validation Accuracy: 21.7857%\n",
      "Epoch 90/500 Training Loss: 0.7288, Training Accuracy: 81.0714%, Validation Loss: 3.6144, Validation Accuracy: 21.4286%\n",
      "Epoch 91/500 Training Loss: 0.7283, Training Accuracy: 80.9821%, Validation Loss: 3.6169, Validation Accuracy: 21.7857%\n",
      "Epoch 92/500 Training Loss: 0.7224, Training Accuracy: 81.1607%, Validation Loss: 3.6366, Validation Accuracy: 21.0714%\n",
      "Epoch 93/500 Training Loss: 0.7199, Training Accuracy: 81.5179%, Validation Loss: 3.6139, Validation Accuracy: 22.5000%\n",
      "Epoch 94/500 Training Loss: 0.7195, Training Accuracy: 81.4286%, Validation Loss: 3.6423, Validation Accuracy: 21.4286%\n",
      "Epoch 95/500 Training Loss: 0.7192, Training Accuracy: 81.2500%, Validation Loss: 3.6331, Validation Accuracy: 21.7857%\n",
      "Epoch 96/500 Training Loss: 0.7150, Training Accuracy: 81.6071%, Validation Loss: 3.6490, Validation Accuracy: 20.7143%\n",
      "Epoch 97/500 Training Loss: 0.7162, Training Accuracy: 80.8929%, Validation Loss: 3.6610, Validation Accuracy: 21.7857%\n",
      "Epoch 98/500 Training Loss: 0.7106, Training Accuracy: 81.8750%, Validation Loss: 3.6586, Validation Accuracy: 21.4286%\n",
      "Epoch 99/500 Training Loss: 0.7130, Training Accuracy: 81.7857%, Validation Loss: 3.6694, Validation Accuracy: 21.7857%\n",
      "Epoch 100/500 Training Loss: 0.7068, Training Accuracy: 81.6964%, Validation Loss: 3.6712, Validation Accuracy: 21.0714%\n",
      "Epoch 101/500 Training Loss: 0.7025, Training Accuracy: 81.6964%, Validation Loss: 3.6679, Validation Accuracy: 22.1429%\n",
      "Epoch 102/500 Training Loss: 0.7011, Training Accuracy: 81.8750%, Validation Loss: 3.6996, Validation Accuracy: 21.0714%\n",
      "Epoch 103/500 Training Loss: 0.7001, Training Accuracy: 82.5000%, Validation Loss: 3.6521, Validation Accuracy: 21.0714%\n",
      "Epoch 104/500 Training Loss: 0.7010, Training Accuracy: 80.8929%, Validation Loss: 3.6919, Validation Accuracy: 20.7143%\n",
      "Epoch 105/500 Training Loss: 0.6965, Training Accuracy: 80.9821%, Validation Loss: 3.6869, Validation Accuracy: 21.7857%\n",
      "Epoch 106/500 Training Loss: 0.6952, Training Accuracy: 82.3214%, Validation Loss: 3.6988, Validation Accuracy: 21.7857%\n",
      "Epoch 107/500 Training Loss: 0.7000, Training Accuracy: 81.6964%, Validation Loss: 3.6845, Validation Accuracy: 21.7857%\n",
      "Epoch 108/500 Training Loss: 0.6907, Training Accuracy: 82.5893%, Validation Loss: 3.7180, Validation Accuracy: 21.7857%\n",
      "Epoch 109/500 Training Loss: 0.6892, Training Accuracy: 82.1429%, Validation Loss: 3.6983, Validation Accuracy: 21.7857%\n",
      "Epoch 110/500 Training Loss: 0.6909, Training Accuracy: 82.5000%, Validation Loss: 3.7503, Validation Accuracy: 21.4286%\n",
      "Epoch 111/500 Training Loss: 0.6858, Training Accuracy: 82.8571%, Validation Loss: 3.7169, Validation Accuracy: 21.4286%\n",
      "Epoch 112/500 Training Loss: 0.6803, Training Accuracy: 82.8571%, Validation Loss: 3.7234, Validation Accuracy: 20.7143%\n",
      "Epoch 113/500 Training Loss: 0.6856, Training Accuracy: 82.5000%, Validation Loss: 3.7453, Validation Accuracy: 20.7143%\n",
      "Epoch 114/500 Training Loss: 0.6799, Training Accuracy: 82.5893%, Validation Loss: 3.7267, Validation Accuracy: 21.4286%\n",
      "Epoch 115/500 Training Loss: 0.6757, Training Accuracy: 82.4107%, Validation Loss: 3.7556, Validation Accuracy: 21.4286%\n",
      "Epoch 116/500 Training Loss: 0.6795, Training Accuracy: 82.5893%, Validation Loss: 3.7451, Validation Accuracy: 21.7857%\n",
      "Epoch 117/500 Training Loss: 0.6741, Training Accuracy: 83.0357%, Validation Loss: 3.7502, Validation Accuracy: 21.0714%\n",
      "Epoch 118/500 Training Loss: 0.6721, Training Accuracy: 83.0357%, Validation Loss: 3.7620, Validation Accuracy: 22.8571%\n",
      "Epoch 119/500 Training Loss: 0.6720, Training Accuracy: 82.6786%, Validation Loss: 3.7585, Validation Accuracy: 20.7143%\n",
      "Epoch 120/500 Training Loss: 0.6747, Training Accuracy: 83.0357%, Validation Loss: 3.7712, Validation Accuracy: 23.2143%\n",
      "Epoch 121/500 Training Loss: 0.6663, Training Accuracy: 83.0357%, Validation Loss: 3.7903, Validation Accuracy: 21.0714%\n",
      "Epoch 122/500 Training Loss: 0.6656, Training Accuracy: 82.8571%, Validation Loss: 3.7624, Validation Accuracy: 22.1429%\n",
      "Epoch 123/500 Training Loss: 0.6635, Training Accuracy: 82.5000%, Validation Loss: 3.7875, Validation Accuracy: 22.1429%\n",
      "Epoch 124/500 Training Loss: 0.6615, Training Accuracy: 83.6607%, Validation Loss: 3.7877, Validation Accuracy: 20.7143%\n",
      "Epoch 125/500 Training Loss: 0.6584, Training Accuracy: 82.7679%, Validation Loss: 3.7930, Validation Accuracy: 22.8571%\n",
      "Epoch 126/500 Training Loss: 0.6579, Training Accuracy: 83.4821%, Validation Loss: 3.7851, Validation Accuracy: 22.5000%\n",
      "Epoch 127/500 Training Loss: 0.6552, Training Accuracy: 83.2143%, Validation Loss: 3.8076, Validation Accuracy: 21.4286%\n",
      "Epoch 128/500 Training Loss: 0.6548, Training Accuracy: 82.8571%, Validation Loss: 3.8086, Validation Accuracy: 21.0714%\n",
      "Epoch 129/500 Training Loss: 0.6537, Training Accuracy: 83.6607%, Validation Loss: 3.8270, Validation Accuracy: 21.0714%\n",
      "Epoch 130/500 Training Loss: 0.6479, Training Accuracy: 83.2143%, Validation Loss: 3.8295, Validation Accuracy: 21.0714%\n",
      "Epoch 131/500 Training Loss: 0.6512, Training Accuracy: 83.2143%, Validation Loss: 3.8184, Validation Accuracy: 21.7857%\n",
      "Epoch 132/500 Training Loss: 0.6460, Training Accuracy: 84.2857%, Validation Loss: 3.8266, Validation Accuracy: 21.4286%\n",
      "Epoch 133/500 Training Loss: 0.6469, Training Accuracy: 84.1964%, Validation Loss: 3.8525, Validation Accuracy: 21.4286%\n",
      "Epoch 134/500 Training Loss: 0.6429, Training Accuracy: 83.4821%, Validation Loss: 3.8370, Validation Accuracy: 21.4286%\n",
      "Epoch 135/500 Training Loss: 0.6456, Training Accuracy: 84.2857%, Validation Loss: 3.8540, Validation Accuracy: 21.4286%\n",
      "Epoch 136/500 Training Loss: 0.6429, Training Accuracy: 83.3036%, Validation Loss: 3.8651, Validation Accuracy: 21.7857%\n",
      "Epoch 137/500 Training Loss: 0.6366, Training Accuracy: 83.7500%, Validation Loss: 3.8471, Validation Accuracy: 22.8571%\n",
      "Epoch 138/500 Training Loss: 0.6389, Training Accuracy: 84.1071%, Validation Loss: 3.8720, Validation Accuracy: 21.0714%\n",
      "Epoch 139/500 Training Loss: 0.6315, Training Accuracy: 84.2857%, Validation Loss: 3.8655, Validation Accuracy: 23.2143%\n",
      "Epoch 140/500 Training Loss: 0.6353, Training Accuracy: 83.4821%, Validation Loss: 3.9095, Validation Accuracy: 21.4286%\n",
      "Epoch 141/500 Training Loss: 0.6406, Training Accuracy: 83.4821%, Validation Loss: 3.8977, Validation Accuracy: 20.7143%\n",
      "Epoch 142/500 Training Loss: 0.6337, Training Accuracy: 83.6607%, Validation Loss: 3.8896, Validation Accuracy: 22.1429%\n",
      "Epoch 143/500 Training Loss: 0.6311, Training Accuracy: 84.1071%, Validation Loss: 3.9009, Validation Accuracy: 22.5000%\n",
      "Epoch 144/500 Training Loss: 0.6269, Training Accuracy: 84.4643%, Validation Loss: 3.8962, Validation Accuracy: 21.4286%\n",
      "Epoch 145/500 Training Loss: 0.6229, Training Accuracy: 84.8214%, Validation Loss: 3.9211, Validation Accuracy: 23.5714%\n",
      "Epoch 146/500 Training Loss: 0.6222, Training Accuracy: 84.7321%, Validation Loss: 3.9103, Validation Accuracy: 21.7857%\n",
      "Epoch 147/500 Training Loss: 0.6172, Training Accuracy: 85.0000%, Validation Loss: 3.9123, Validation Accuracy: 22.8571%\n",
      "Epoch 148/500 Training Loss: 0.6191, Training Accuracy: 85.1786%, Validation Loss: 3.9300, Validation Accuracy: 21.7857%\n",
      "Epoch 149/500 Training Loss: 0.6194, Training Accuracy: 84.9107%, Validation Loss: 3.9088, Validation Accuracy: 21.7857%\n",
      "Epoch 150/500 Training Loss: 0.6168, Training Accuracy: 84.8214%, Validation Loss: 3.9649, Validation Accuracy: 21.4286%\n",
      "Epoch 151/500 Training Loss: 0.6161, Training Accuracy: 85.0000%, Validation Loss: 3.9398, Validation Accuracy: 21.7857%\n",
      "Epoch 152/500 Training Loss: 0.6097, Training Accuracy: 85.4464%, Validation Loss: 3.9651, Validation Accuracy: 22.1429%\n",
      "Epoch 153/500 Training Loss: 0.6080, Training Accuracy: 84.2857%, Validation Loss: 3.9344, Validation Accuracy: 23.2143%\n",
      "Epoch 154/500 Training Loss: 0.6099, Training Accuracy: 84.7321%, Validation Loss: 3.9384, Validation Accuracy: 22.1429%\n",
      "Epoch 155/500 Training Loss: 0.6095, Training Accuracy: 84.7321%, Validation Loss: 3.9433, Validation Accuracy: 22.5000%\n",
      "Epoch 156/500 Training Loss: 0.6053, Training Accuracy: 85.3571%, Validation Loss: 3.9672, Validation Accuracy: 22.5000%\n",
      "Epoch 157/500 Training Loss: 0.6026, Training Accuracy: 85.0000%, Validation Loss: 3.9458, Validation Accuracy: 23.2143%\n",
      "Epoch 158/500 Training Loss: 0.5970, Training Accuracy: 84.7321%, Validation Loss: 3.9724, Validation Accuracy: 22.8571%\n",
      "Epoch 159/500 Training Loss: 0.5971, Training Accuracy: 85.0893%, Validation Loss: 3.9684, Validation Accuracy: 22.5000%\n",
      "Epoch 160/500 Training Loss: 0.5980, Training Accuracy: 85.4464%, Validation Loss: 3.9823, Validation Accuracy: 22.8571%\n",
      "Epoch 161/500 Training Loss: 0.5951, Training Accuracy: 85.2679%, Validation Loss: 3.9946, Validation Accuracy: 21.4286%\n",
      "Epoch 162/500 Training Loss: 0.5967, Training Accuracy: 85.9821%, Validation Loss: 3.9654, Validation Accuracy: 22.8571%\n",
      "Epoch 163/500 Training Loss: 0.5890, Training Accuracy: 85.7143%, Validation Loss: 3.9778, Validation Accuracy: 23.5714%\n",
      "Epoch 164/500 Training Loss: 0.5925, Training Accuracy: 85.8036%, Validation Loss: 4.0139, Validation Accuracy: 23.2143%\n",
      "Epoch 165/500 Training Loss: 0.5979, Training Accuracy: 85.3571%, Validation Loss: 3.9943, Validation Accuracy: 23.2143%\n",
      "Epoch 166/500 Training Loss: 0.5897, Training Accuracy: 85.6250%, Validation Loss: 4.0008, Validation Accuracy: 23.2143%\n",
      "Epoch 167/500 Training Loss: 0.5862, Training Accuracy: 85.9821%, Validation Loss: 4.0454, Validation Accuracy: 22.8571%\n",
      "Epoch 168/500 Training Loss: 0.5891, Training Accuracy: 85.6250%, Validation Loss: 4.0093, Validation Accuracy: 22.1429%\n",
      "Epoch 169/500 Training Loss: 0.5840, Training Accuracy: 85.7143%, Validation Loss: 4.0555, Validation Accuracy: 21.4286%\n",
      "Epoch 170/500 Training Loss: 0.5837, Training Accuracy: 86.0714%, Validation Loss: 4.0311, Validation Accuracy: 22.5000%\n",
      "Epoch 171/500 Training Loss: 0.5822, Training Accuracy: 85.9821%, Validation Loss: 4.0407, Validation Accuracy: 23.2143%\n",
      "Epoch 172/500 Training Loss: 0.5793, Training Accuracy: 86.2500%, Validation Loss: 4.0330, Validation Accuracy: 22.8571%\n",
      "Epoch 173/500 Training Loss: 0.5742, Training Accuracy: 86.1607%, Validation Loss: 4.0232, Validation Accuracy: 22.1429%\n",
      "Epoch 174/500 Training Loss: 0.5781, Training Accuracy: 85.9821%, Validation Loss: 4.0398, Validation Accuracy: 21.4286%\n",
      "Epoch 175/500 Training Loss: 0.5749, Training Accuracy: 86.5179%, Validation Loss: 4.0525, Validation Accuracy: 23.2143%\n",
      "Epoch 176/500 Training Loss: 0.5728, Training Accuracy: 87.2321%, Validation Loss: 4.0511, Validation Accuracy: 23.2143%\n",
      "Epoch 177/500 Training Loss: 0.5725, Training Accuracy: 86.1607%, Validation Loss: 4.0651, Validation Accuracy: 23.5714%\n",
      "Epoch 178/500 Training Loss: 0.5699, Training Accuracy: 86.6964%, Validation Loss: 4.0861, Validation Accuracy: 23.2143%\n",
      "Epoch 179/500 Training Loss: 0.5694, Training Accuracy: 86.3393%, Validation Loss: 4.0831, Validation Accuracy: 22.5000%\n",
      "Epoch 180/500 Training Loss: 0.5677, Training Accuracy: 86.2500%, Validation Loss: 4.0978, Validation Accuracy: 22.1429%\n",
      "Epoch 181/500 Training Loss: 0.5678, Training Accuracy: 86.6071%, Validation Loss: 4.1027, Validation Accuracy: 23.2143%\n",
      "Epoch 182/500 Training Loss: 0.5626, Training Accuracy: 87.0536%, Validation Loss: 4.0835, Validation Accuracy: 22.8571%\n",
      "Epoch 183/500 Training Loss: 0.5627, Training Accuracy: 86.6964%, Validation Loss: 4.1154, Validation Accuracy: 23.2143%\n",
      "Epoch 184/500 Training Loss: 0.5601, Training Accuracy: 87.0536%, Validation Loss: 4.0943, Validation Accuracy: 23.2143%\n",
      "Epoch 185/500 Training Loss: 0.5603, Training Accuracy: 86.9643%, Validation Loss: 4.1355, Validation Accuracy: 22.5000%\n",
      "Epoch 186/500 Training Loss: 0.5626, Training Accuracy: 86.3393%, Validation Loss: 4.1172, Validation Accuracy: 23.2143%\n",
      "Epoch 187/500 Training Loss: 0.5584, Training Accuracy: 87.8571%, Validation Loss: 4.1298, Validation Accuracy: 23.5714%\n",
      "Epoch 188/500 Training Loss: 0.5533, Training Accuracy: 87.5000%, Validation Loss: 4.1134, Validation Accuracy: 22.5000%\n",
      "Epoch 189/500 Training Loss: 0.5523, Training Accuracy: 86.6071%, Validation Loss: 4.1563, Validation Accuracy: 22.1429%\n",
      "Epoch 190/500 Training Loss: 0.5530, Training Accuracy: 87.3214%, Validation Loss: 4.1209, Validation Accuracy: 22.8571%\n",
      "Epoch 191/500 Training Loss: 0.5473, Training Accuracy: 87.6786%, Validation Loss: 4.1434, Validation Accuracy: 21.7857%\n",
      "Epoch 192/500 Training Loss: 0.5483, Training Accuracy: 87.8571%, Validation Loss: 4.1604, Validation Accuracy: 23.2143%\n",
      "Epoch 193/500 Training Loss: 0.5484, Training Accuracy: 87.2321%, Validation Loss: 4.1379, Validation Accuracy: 23.5714%\n",
      "Epoch 194/500 Training Loss: 0.5473, Training Accuracy: 87.7679%, Validation Loss: 4.1624, Validation Accuracy: 23.9286%\n",
      "Epoch 195/500 Training Loss: 0.5469, Training Accuracy: 86.8750%, Validation Loss: 4.1501, Validation Accuracy: 23.9286%\n",
      "Epoch 196/500 Training Loss: 0.5406, Training Accuracy: 87.4107%, Validation Loss: 4.1612, Validation Accuracy: 23.2143%\n",
      "Epoch 197/500 Training Loss: 0.5450, Training Accuracy: 87.3214%, Validation Loss: 4.1621, Validation Accuracy: 24.6429%\n",
      "Epoch 198/500 Training Loss: 0.5420, Training Accuracy: 86.6964%, Validation Loss: 4.2185, Validation Accuracy: 21.4286%\n",
      "Epoch 199/500 Training Loss: 0.5359, Training Accuracy: 87.4107%, Validation Loss: 4.1907, Validation Accuracy: 21.7857%\n",
      "Epoch 200/500 Training Loss: 0.5380, Training Accuracy: 87.9464%, Validation Loss: 4.1821, Validation Accuracy: 24.2857%\n",
      "Epoch 201/500 Training Loss: 0.5352, Training Accuracy: 87.5893%, Validation Loss: 4.1933, Validation Accuracy: 22.1429%\n",
      "Epoch 202/500 Training Loss: 0.5299, Training Accuracy: 87.7679%, Validation Loss: 4.2043, Validation Accuracy: 22.5000%\n",
      "Epoch 203/500 Training Loss: 0.5309, Training Accuracy: 88.3036%, Validation Loss: 4.1965, Validation Accuracy: 22.1429%\n",
      "Epoch 204/500 Training Loss: 0.5341, Training Accuracy: 87.4107%, Validation Loss: 4.2233, Validation Accuracy: 24.2857%\n",
      "Epoch 205/500 Training Loss: 0.5326, Training Accuracy: 88.7500%, Validation Loss: 4.2245, Validation Accuracy: 21.7857%\n",
      "Epoch 206/500 Training Loss: 0.5289, Training Accuracy: 87.1429%, Validation Loss: 4.2236, Validation Accuracy: 22.5000%\n",
      "Epoch 207/500 Training Loss: 0.5272, Training Accuracy: 88.5714%, Validation Loss: 4.2179, Validation Accuracy: 22.8571%\n",
      "Epoch 208/500 Training Loss: 0.5250, Training Accuracy: 88.3929%, Validation Loss: 4.2451, Validation Accuracy: 23.9286%\n",
      "Epoch 209/500 Training Loss: 0.5189, Training Accuracy: 88.4821%, Validation Loss: 4.2508, Validation Accuracy: 22.8571%\n",
      "Epoch 210/500 Training Loss: 0.5199, Training Accuracy: 89.1071%, Validation Loss: 4.2680, Validation Accuracy: 23.5714%\n",
      "Epoch 211/500 Training Loss: 0.5198, Training Accuracy: 88.3929%, Validation Loss: 4.2483, Validation Accuracy: 22.5000%\n",
      "Epoch 212/500 Training Loss: 0.5229, Training Accuracy: 87.3214%, Validation Loss: 4.2904, Validation Accuracy: 21.7857%\n",
      "Epoch 213/500 Training Loss: 0.5185, Training Accuracy: 88.8393%, Validation Loss: 4.2659, Validation Accuracy: 23.9286%\n",
      "Epoch 214/500 Training Loss: 0.5131, Training Accuracy: 88.3929%, Validation Loss: 4.2805, Validation Accuracy: 22.5000%\n",
      "Epoch 215/500 Training Loss: 0.5136, Training Accuracy: 88.2143%, Validation Loss: 4.2872, Validation Accuracy: 22.8571%\n",
      "Epoch 216/500 Training Loss: 0.5155, Training Accuracy: 88.8393%, Validation Loss: 4.2665, Validation Accuracy: 22.8571%\n",
      "Epoch 217/500 Training Loss: 0.5097, Training Accuracy: 89.0179%, Validation Loss: 4.3112, Validation Accuracy: 23.5714%\n",
      "Epoch 218/500 Training Loss: 0.5055, Training Accuracy: 89.1071%, Validation Loss: 4.2923, Validation Accuracy: 23.5714%\n",
      "Epoch 219/500 Training Loss: 0.5103, Training Accuracy: 88.5714%, Validation Loss: 4.2975, Validation Accuracy: 23.2143%\n",
      "Epoch 220/500 Training Loss: 0.5063, Training Accuracy: 89.0179%, Validation Loss: 4.3274, Validation Accuracy: 23.2143%\n",
      "Epoch 221/500 Training Loss: 0.5072, Training Accuracy: 89.3750%, Validation Loss: 4.3063, Validation Accuracy: 23.9286%\n",
      "Epoch 222/500 Training Loss: 0.5061, Training Accuracy: 88.6607%, Validation Loss: 4.3478, Validation Accuracy: 22.5000%\n",
      "Epoch 223/500 Training Loss: 0.5037, Training Accuracy: 88.8393%, Validation Loss: 4.3034, Validation Accuracy: 24.6429%\n",
      "Epoch 224/500 Training Loss: 0.5019, Training Accuracy: 89.1964%, Validation Loss: 4.3130, Validation Accuracy: 23.2143%\n",
      "Epoch 225/500 Training Loss: 0.5000, Training Accuracy: 89.1071%, Validation Loss: 4.3462, Validation Accuracy: 22.8571%\n",
      "Epoch 226/500 Training Loss: 0.4960, Training Accuracy: 89.5536%, Validation Loss: 4.3451, Validation Accuracy: 23.5714%\n",
      "Epoch 227/500 Training Loss: 0.4984, Training Accuracy: 89.0179%, Validation Loss: 4.3678, Validation Accuracy: 22.5000%\n",
      "Epoch 228/500 Training Loss: 0.4961, Training Accuracy: 89.2857%, Validation Loss: 4.3532, Validation Accuracy: 23.5714%\n",
      "Epoch 229/500 Training Loss: 0.4910, Training Accuracy: 89.8214%, Validation Loss: 4.3634, Validation Accuracy: 22.1429%\n",
      "Epoch 230/500 Training Loss: 0.4919, Training Accuracy: 89.0179%, Validation Loss: 4.3871, Validation Accuracy: 23.5714%\n",
      "Epoch 231/500 Training Loss: 0.4898, Training Accuracy: 89.1964%, Validation Loss: 4.3424, Validation Accuracy: 22.8571%\n",
      "Epoch 232/500 Training Loss: 0.4891, Training Accuracy: 89.3750%, Validation Loss: 4.4028, Validation Accuracy: 23.9286%\n",
      "Epoch 233/500 Training Loss: 0.4930, Training Accuracy: 89.1964%, Validation Loss: 4.3749, Validation Accuracy: 23.9286%\n",
      "Epoch 234/500 Training Loss: 0.4885, Training Accuracy: 89.4643%, Validation Loss: 4.3756, Validation Accuracy: 23.5714%\n",
      "Epoch 235/500 Training Loss: 0.4863, Training Accuracy: 89.2857%, Validation Loss: 4.3887, Validation Accuracy: 23.9286%\n",
      "Epoch 236/500 Training Loss: 0.4837, Training Accuracy: 90.0893%, Validation Loss: 4.4374, Validation Accuracy: 23.2143%\n",
      "Epoch 237/500 Training Loss: 0.4804, Training Accuracy: 89.7321%, Validation Loss: 4.4091, Validation Accuracy: 23.9286%\n",
      "Epoch 238/500 Training Loss: 0.4840, Training Accuracy: 89.9107%, Validation Loss: 4.4125, Validation Accuracy: 22.5000%\n",
      "Epoch 239/500 Training Loss: 0.4819, Training Accuracy: 89.3750%, Validation Loss: 4.4435, Validation Accuracy: 22.8571%\n",
      "Epoch 240/500 Training Loss: 0.4790, Training Accuracy: 89.8214%, Validation Loss: 4.4435, Validation Accuracy: 23.2143%\n",
      "Epoch 241/500 Training Loss: 0.4757, Training Accuracy: 90.2679%, Validation Loss: 4.4139, Validation Accuracy: 22.5000%\n",
      "Epoch 242/500 Training Loss: 0.4798, Training Accuracy: 89.6429%, Validation Loss: 4.4408, Validation Accuracy: 22.5000%\n",
      "Epoch 243/500 Training Loss: 0.4751, Training Accuracy: 89.4643%, Validation Loss: 4.4257, Validation Accuracy: 23.9286%\n",
      "Epoch 244/500 Training Loss: 0.4725, Training Accuracy: 89.8214%, Validation Loss: 4.4333, Validation Accuracy: 23.5714%\n",
      "Epoch 245/500 Training Loss: 0.4744, Training Accuracy: 89.5536%, Validation Loss: 4.4700, Validation Accuracy: 22.5000%\n",
      "Epoch 246/500 Training Loss: 0.4682, Training Accuracy: 90.2679%, Validation Loss: 4.4350, Validation Accuracy: 23.5714%\n",
      "Epoch 247/500 Training Loss: 0.4691, Training Accuracy: 89.6429%, Validation Loss: 4.4439, Validation Accuracy: 22.8571%\n",
      "Epoch 248/500 Training Loss: 0.4722, Training Accuracy: 90.0000%, Validation Loss: 4.4719, Validation Accuracy: 23.5714%\n",
      "Epoch 249/500 Training Loss: 0.4679, Training Accuracy: 89.9107%, Validation Loss: 4.4661, Validation Accuracy: 22.1429%\n",
      "Epoch 250/500 Training Loss: 0.4657, Training Accuracy: 90.0000%, Validation Loss: 4.4725, Validation Accuracy: 22.8571%\n",
      "Epoch 251/500 Training Loss: 0.4650, Training Accuracy: 90.4464%, Validation Loss: 4.4847, Validation Accuracy: 23.5714%\n",
      "Epoch 252/500 Training Loss: 0.4585, Training Accuracy: 90.8929%, Validation Loss: 4.4852, Validation Accuracy: 23.5714%\n",
      "Epoch 253/500 Training Loss: 0.4629, Training Accuracy: 90.1786%, Validation Loss: 4.5024, Validation Accuracy: 22.8571%\n",
      "Epoch 254/500 Training Loss: 0.4620, Training Accuracy: 89.9107%, Validation Loss: 4.5075, Validation Accuracy: 22.8571%\n",
      "Epoch 255/500 Training Loss: 0.4536, Training Accuracy: 91.2500%, Validation Loss: 4.5107, Validation Accuracy: 23.2143%\n",
      "Epoch 256/500 Training Loss: 0.4566, Training Accuracy: 90.8929%, Validation Loss: 4.5071, Validation Accuracy: 22.8571%\n",
      "Epoch 257/500 Training Loss: 0.4546, Training Accuracy: 90.5357%, Validation Loss: 4.5045, Validation Accuracy: 22.1429%\n",
      "Epoch 258/500 Training Loss: 0.4500, Training Accuracy: 90.5357%, Validation Loss: 4.5221, Validation Accuracy: 22.5000%\n",
      "Epoch 259/500 Training Loss: 0.4563, Training Accuracy: 90.8036%, Validation Loss: 4.5480, Validation Accuracy: 23.5714%\n",
      "Epoch 260/500 Training Loss: 0.4514, Training Accuracy: 90.8929%, Validation Loss: 4.5136, Validation Accuracy: 22.8571%\n",
      "Epoch 261/500 Training Loss: 0.4491, Training Accuracy: 90.8929%, Validation Loss: 4.5362, Validation Accuracy: 22.8571%\n",
      "Epoch 262/500 Training Loss: 0.4493, Training Accuracy: 90.7143%, Validation Loss: 4.5623, Validation Accuracy: 22.5000%\n",
      "Epoch 263/500 Training Loss: 0.4461, Training Accuracy: 90.5357%, Validation Loss: 4.5416, Validation Accuracy: 23.9286%\n",
      "Epoch 264/500 Training Loss: 0.4486, Training Accuracy: 91.2500%, Validation Loss: 4.5747, Validation Accuracy: 22.8571%\n",
      "Epoch 265/500 Training Loss: 0.4470, Training Accuracy: 90.7143%, Validation Loss: 4.5678, Validation Accuracy: 23.2143%\n",
      "Epoch 266/500 Training Loss: 0.4413, Training Accuracy: 90.8929%, Validation Loss: 4.5583, Validation Accuracy: 22.1429%\n",
      "Epoch 267/500 Training Loss: 0.4404, Training Accuracy: 91.1607%, Validation Loss: 4.5729, Validation Accuracy: 22.5000%\n",
      "Epoch 268/500 Training Loss: 0.4392, Training Accuracy: 91.0714%, Validation Loss: 4.5661, Validation Accuracy: 22.5000%\n",
      "Epoch 269/500 Training Loss: 0.4380, Training Accuracy: 91.0714%, Validation Loss: 4.5856, Validation Accuracy: 23.5714%\n",
      "Epoch 270/500 Training Loss: 0.4353, Training Accuracy: 91.4286%, Validation Loss: 4.6199, Validation Accuracy: 23.5714%\n",
      "Epoch 271/500 Training Loss: 0.4390, Training Accuracy: 91.7857%, Validation Loss: 4.6025, Validation Accuracy: 22.5000%\n",
      "Epoch 272/500 Training Loss: 0.4355, Training Accuracy: 91.4286%, Validation Loss: 4.6114, Validation Accuracy: 22.1429%\n",
      "Epoch 273/500 Training Loss: 0.4334, Training Accuracy: 91.2500%, Validation Loss: 4.5905, Validation Accuracy: 22.1429%\n",
      "Epoch 274/500 Training Loss: 0.4295, Training Accuracy: 91.6964%, Validation Loss: 4.5884, Validation Accuracy: 24.6429%\n",
      "Epoch 275/500 Training Loss: 0.4304, Training Accuracy: 91.6071%, Validation Loss: 4.6031, Validation Accuracy: 23.2143%\n",
      "Epoch 276/500 Training Loss: 0.4321, Training Accuracy: 91.6071%, Validation Loss: 4.6434, Validation Accuracy: 23.9286%\n",
      "Epoch 277/500 Training Loss: 0.4294, Training Accuracy: 91.2500%, Validation Loss: 4.6309, Validation Accuracy: 23.2143%\n",
      "Epoch 278/500 Training Loss: 0.4314, Training Accuracy: 91.2500%, Validation Loss: 4.6524, Validation Accuracy: 21.4286%\n",
      "Epoch 279/500 Training Loss: 0.4259, Training Accuracy: 91.3393%, Validation Loss: 4.6504, Validation Accuracy: 24.6429%\n",
      "Epoch 280/500 Training Loss: 0.4261, Training Accuracy: 91.2500%, Validation Loss: 4.6518, Validation Accuracy: 22.8571%\n",
      "Epoch 281/500 Training Loss: 0.4213, Training Accuracy: 92.2321%, Validation Loss: 4.6732, Validation Accuracy: 23.2143%\n",
      "Epoch 282/500 Training Loss: 0.4220, Training Accuracy: 91.3393%, Validation Loss: 4.6416, Validation Accuracy: 22.1429%\n",
      "Epoch 283/500 Training Loss: 0.4205, Training Accuracy: 92.5000%, Validation Loss: 4.6336, Validation Accuracy: 23.2143%\n",
      "Epoch 284/500 Training Loss: 0.4221, Training Accuracy: 91.4286%, Validation Loss: 4.7069, Validation Accuracy: 21.7857%\n",
      "Epoch 285/500 Training Loss: 0.4168, Training Accuracy: 91.4286%, Validation Loss: 4.6694, Validation Accuracy: 22.5000%\n",
      "Epoch 286/500 Training Loss: 0.4170, Training Accuracy: 92.3214%, Validation Loss: 4.6828, Validation Accuracy: 22.5000%\n",
      "Epoch 287/500 Training Loss: 0.4167, Training Accuracy: 91.4286%, Validation Loss: 4.6864, Validation Accuracy: 22.5000%\n",
      "Epoch 288/500 Training Loss: 0.4102, Training Accuracy: 92.6786%, Validation Loss: 4.7211, Validation Accuracy: 22.1429%\n",
      "Epoch 289/500 Training Loss: 0.4145, Training Accuracy: 91.3393%, Validation Loss: 4.7141, Validation Accuracy: 22.8571%\n",
      "Epoch 290/500 Training Loss: 0.4100, Training Accuracy: 92.4107%, Validation Loss: 4.6784, Validation Accuracy: 22.5000%\n",
      "Epoch 291/500 Training Loss: 0.4112, Training Accuracy: 92.4107%, Validation Loss: 4.6924, Validation Accuracy: 24.2857%\n",
      "Epoch 292/500 Training Loss: 0.4116, Training Accuracy: 91.8750%, Validation Loss: 4.7264, Validation Accuracy: 22.5000%\n",
      "Epoch 293/500 Training Loss: 0.4064, Training Accuracy: 92.9464%, Validation Loss: 4.7335, Validation Accuracy: 23.2143%\n",
      "Epoch 294/500 Training Loss: 0.4029, Training Accuracy: 92.1429%, Validation Loss: 4.7375, Validation Accuracy: 22.8571%\n",
      "Epoch 295/500 Training Loss: 0.4039, Training Accuracy: 92.5000%, Validation Loss: 4.7516, Validation Accuracy: 22.8571%\n",
      "Epoch 296/500 Training Loss: 0.4078, Training Accuracy: 91.8750%, Validation Loss: 4.7524, Validation Accuracy: 23.9286%\n",
      "Epoch 297/500 Training Loss: 0.4054, Training Accuracy: 92.3214%, Validation Loss: 4.7470, Validation Accuracy: 22.8571%\n",
      "Epoch 298/500 Training Loss: 0.4060, Training Accuracy: 92.9464%, Validation Loss: 4.7599, Validation Accuracy: 22.5000%\n",
      "Epoch 299/500 Training Loss: 0.4017, Training Accuracy: 92.3214%, Validation Loss: 4.7455, Validation Accuracy: 22.5000%\n",
      "Epoch 300/500 Training Loss: 0.3968, Training Accuracy: 93.2143%, Validation Loss: 4.7415, Validation Accuracy: 23.5714%\n",
      "Epoch 301/500 Training Loss: 0.3976, Training Accuracy: 92.4107%, Validation Loss: 4.7711, Validation Accuracy: 22.1429%\n",
      "Epoch 302/500 Training Loss: 0.3970, Training Accuracy: 92.1429%, Validation Loss: 4.7764, Validation Accuracy: 23.2143%\n",
      "Epoch 303/500 Training Loss: 0.3973, Training Accuracy: 92.7679%, Validation Loss: 4.7556, Validation Accuracy: 23.9286%\n",
      "Epoch 304/500 Training Loss: 0.3952, Training Accuracy: 93.2143%, Validation Loss: 4.7942, Validation Accuracy: 23.2143%\n",
      "Epoch 305/500 Training Loss: 0.3951, Training Accuracy: 92.4107%, Validation Loss: 4.7888, Validation Accuracy: 22.8571%\n",
      "Epoch 306/500 Training Loss: 0.3935, Training Accuracy: 92.4107%, Validation Loss: 4.7879, Validation Accuracy: 22.8571%\n",
      "Epoch 307/500 Training Loss: 0.3917, Training Accuracy: 93.1250%, Validation Loss: 4.8052, Validation Accuracy: 21.7857%\n",
      "Epoch 308/500 Training Loss: 0.3907, Training Accuracy: 92.9464%, Validation Loss: 4.7989, Validation Accuracy: 23.9286%\n",
      "Epoch 309/500 Training Loss: 0.3863, Training Accuracy: 92.6786%, Validation Loss: 4.8235, Validation Accuracy: 22.8571%\n",
      "Epoch 310/500 Training Loss: 0.3867, Training Accuracy: 93.3929%, Validation Loss: 4.8146, Validation Accuracy: 23.9286%\n",
      "Epoch 311/500 Training Loss: 0.3878, Training Accuracy: 93.2143%, Validation Loss: 4.8692, Validation Accuracy: 23.2143%\n",
      "Epoch 312/500 Training Loss: 0.3870, Training Accuracy: 93.0357%, Validation Loss: 4.8351, Validation Accuracy: 21.7857%\n",
      "Epoch 313/500 Training Loss: 0.3867, Training Accuracy: 92.9464%, Validation Loss: 4.8047, Validation Accuracy: 22.8571%\n",
      "Epoch 314/500 Training Loss: 0.3831, Training Accuracy: 92.9464%, Validation Loss: 4.8280, Validation Accuracy: 23.9286%\n",
      "Epoch 315/500 Training Loss: 0.3825, Training Accuracy: 92.9464%, Validation Loss: 4.8362, Validation Accuracy: 22.8571%\n",
      "Epoch 316/500 Training Loss: 0.3820, Training Accuracy: 93.0357%, Validation Loss: 4.8576, Validation Accuracy: 22.8571%\n",
      "Epoch 317/500 Training Loss: 0.3791, Training Accuracy: 93.7500%, Validation Loss: 4.8566, Validation Accuracy: 23.9286%\n",
      "Epoch 318/500 Training Loss: 0.3795, Training Accuracy: 93.2143%, Validation Loss: 4.8501, Validation Accuracy: 23.9286%\n",
      "Epoch 319/500 Training Loss: 0.3786, Training Accuracy: 93.1250%, Validation Loss: 4.8836, Validation Accuracy: 23.5714%\n",
      "Epoch 320/500 Training Loss: 0.3743, Training Accuracy: 93.8393%, Validation Loss: 4.8836, Validation Accuracy: 23.2143%\n",
      "Epoch 321/500 Training Loss: 0.3810, Training Accuracy: 93.1250%, Validation Loss: 4.9040, Validation Accuracy: 22.8571%\n",
      "Epoch 322/500 Training Loss: 0.3759, Training Accuracy: 93.3036%, Validation Loss: 4.9152, Validation Accuracy: 23.5714%\n",
      "Epoch 323/500 Training Loss: 0.3745, Training Accuracy: 93.1250%, Validation Loss: 4.9095, Validation Accuracy: 22.5000%\n",
      "Epoch 324/500 Training Loss: 0.3757, Training Accuracy: 93.1250%, Validation Loss: 4.9130, Validation Accuracy: 23.2143%\n",
      "Epoch 325/500 Training Loss: 0.3725, Training Accuracy: 93.4821%, Validation Loss: 4.8787, Validation Accuracy: 23.5714%\n",
      "Epoch 326/500 Training Loss: 0.3686, Training Accuracy: 93.6607%, Validation Loss: 4.9557, Validation Accuracy: 23.2143%\n",
      "Epoch 327/500 Training Loss: 0.3688, Training Accuracy: 93.7500%, Validation Loss: 4.9096, Validation Accuracy: 23.9286%\n",
      "Epoch 328/500 Training Loss: 0.3650, Training Accuracy: 93.1250%, Validation Loss: 4.8998, Validation Accuracy: 23.5714%\n",
      "Epoch 329/500 Training Loss: 0.3637, Training Accuracy: 93.3929%, Validation Loss: 4.9494, Validation Accuracy: 23.2143%\n",
      "Epoch 330/500 Training Loss: 0.3651, Training Accuracy: 93.2143%, Validation Loss: 4.9134, Validation Accuracy: 23.2143%\n",
      "Epoch 331/500 Training Loss: 0.3627, Training Accuracy: 94.9107%, Validation Loss: 4.9384, Validation Accuracy: 22.8571%\n",
      "Epoch 332/500 Training Loss: 0.3659, Training Accuracy: 93.1250%, Validation Loss: 4.9494, Validation Accuracy: 22.5000%\n",
      "Epoch 333/500 Training Loss: 0.3640, Training Accuracy: 93.6607%, Validation Loss: 4.9691, Validation Accuracy: 23.2143%\n",
      "Epoch 334/500 Training Loss: 0.3579, Training Accuracy: 94.2857%, Validation Loss: 4.9645, Validation Accuracy: 23.5714%\n",
      "Epoch 335/500 Training Loss: 0.3627, Training Accuracy: 93.2143%, Validation Loss: 4.9661, Validation Accuracy: 22.8571%\n",
      "Epoch 336/500 Training Loss: 0.3608, Training Accuracy: 93.9286%, Validation Loss: 4.9699, Validation Accuracy: 22.8571%\n",
      "Epoch 337/500 Training Loss: 0.3581, Training Accuracy: 93.7500%, Validation Loss: 5.0263, Validation Accuracy: 22.5000%\n",
      "Epoch 338/500 Training Loss: 0.3580, Training Accuracy: 93.3036%, Validation Loss: 4.9952, Validation Accuracy: 22.5000%\n",
      "Epoch 339/500 Training Loss: 0.3561, Training Accuracy: 94.2857%, Validation Loss: 4.9927, Validation Accuracy: 22.8571%\n",
      "Epoch 340/500 Training Loss: 0.3544, Training Accuracy: 94.1071%, Validation Loss: 5.0070, Validation Accuracy: 23.5714%\n",
      "Epoch 341/500 Training Loss: 0.3530, Training Accuracy: 94.1071%, Validation Loss: 4.9948, Validation Accuracy: 22.1429%\n",
      "Epoch 342/500 Training Loss: 0.3506, Training Accuracy: 94.3750%, Validation Loss: 5.0066, Validation Accuracy: 22.8571%\n",
      "Epoch 343/500 Training Loss: 0.3519, Training Accuracy: 94.3750%, Validation Loss: 5.0118, Validation Accuracy: 21.7857%\n",
      "Epoch 344/500 Training Loss: 0.3495, Training Accuracy: 94.1964%, Validation Loss: 5.0608, Validation Accuracy: 22.5000%\n",
      "Epoch 345/500 Training Loss: 0.3500, Training Accuracy: 94.5536%, Validation Loss: 5.0164, Validation Accuracy: 23.9286%\n",
      "Epoch 346/500 Training Loss: 0.3487, Training Accuracy: 94.4643%, Validation Loss: 5.0432, Validation Accuracy: 23.2143%\n",
      "Epoch 347/500 Training Loss: 0.3453, Training Accuracy: 93.9286%, Validation Loss: 5.0501, Validation Accuracy: 23.2143%\n",
      "Epoch 348/500 Training Loss: 0.3447, Training Accuracy: 94.6429%, Validation Loss: 5.0479, Validation Accuracy: 23.2143%\n",
      "Epoch 349/500 Training Loss: 0.3437, Training Accuracy: 94.0179%, Validation Loss: 5.0260, Validation Accuracy: 23.5714%\n",
      "Epoch 350/500 Training Loss: 0.3439, Training Accuracy: 94.8214%, Validation Loss: 5.0893, Validation Accuracy: 23.9286%\n",
      "Epoch 351/500 Training Loss: 0.3410, Training Accuracy: 94.4643%, Validation Loss: 5.0472, Validation Accuracy: 22.5000%\n",
      "Epoch 352/500 Training Loss: 0.3400, Training Accuracy: 94.9107%, Validation Loss: 5.0948, Validation Accuracy: 23.9286%\n",
      "Epoch 353/500 Training Loss: 0.3387, Training Accuracy: 94.5536%, Validation Loss: 5.0914, Validation Accuracy: 23.2143%\n",
      "Epoch 354/500 Training Loss: 0.3418, Training Accuracy: 94.1071%, Validation Loss: 5.1139, Validation Accuracy: 22.1429%\n",
      "Epoch 355/500 Training Loss: 0.3381, Training Accuracy: 94.1964%, Validation Loss: 5.0954, Validation Accuracy: 21.4286%\n",
      "Epoch 356/500 Training Loss: 0.3416, Training Accuracy: 94.0179%, Validation Loss: 5.0898, Validation Accuracy: 23.5714%\n",
      "Epoch 357/500 Training Loss: 0.3348, Training Accuracy: 94.2857%, Validation Loss: 5.1196, Validation Accuracy: 21.4286%\n",
      "Epoch 358/500 Training Loss: 0.3322, Training Accuracy: 95.0893%, Validation Loss: 5.1181, Validation Accuracy: 22.8571%\n",
      "Epoch 359/500 Training Loss: 0.3306, Training Accuracy: 94.7321%, Validation Loss: 5.1245, Validation Accuracy: 21.7857%\n",
      "Epoch 360/500 Training Loss: 0.3340, Training Accuracy: 94.6429%, Validation Loss: 5.1262, Validation Accuracy: 22.5000%\n",
      "Epoch 361/500 Training Loss: 0.3293, Training Accuracy: 95.0000%, Validation Loss: 5.1258, Validation Accuracy: 22.8571%\n",
      "Epoch 362/500 Training Loss: 0.3341, Training Accuracy: 94.2857%, Validation Loss: 5.1405, Validation Accuracy: 23.5714%\n",
      "Epoch 363/500 Training Loss: 0.3310, Training Accuracy: 94.2857%, Validation Loss: 5.1180, Validation Accuracy: 22.1429%\n",
      "Epoch 364/500 Training Loss: 0.3255, Training Accuracy: 95.1786%, Validation Loss: 5.1419, Validation Accuracy: 23.5714%\n",
      "Epoch 365/500 Training Loss: 0.3247, Training Accuracy: 94.7321%, Validation Loss: 5.1513, Validation Accuracy: 22.5000%\n",
      "Epoch 366/500 Training Loss: 0.3229, Training Accuracy: 95.0000%, Validation Loss: 5.1606, Validation Accuracy: 23.2143%\n",
      "Epoch 367/500 Training Loss: 0.3264, Training Accuracy: 94.8214%, Validation Loss: 5.1929, Validation Accuracy: 22.8571%\n",
      "Epoch 368/500 Training Loss: 0.3231, Training Accuracy: 95.0000%, Validation Loss: 5.2014, Validation Accuracy: 23.5714%\n",
      "Epoch 369/500 Training Loss: 0.3281, Training Accuracy: 94.2857%, Validation Loss: 5.1662, Validation Accuracy: 23.5714%\n",
      "Epoch 370/500 Training Loss: 0.3275, Training Accuracy: 94.7321%, Validation Loss: 5.1851, Validation Accuracy: 23.2143%\n",
      "Epoch 371/500 Training Loss: 0.3206, Training Accuracy: 95.0000%, Validation Loss: 5.1754, Validation Accuracy: 23.9286%\n",
      "Epoch 372/500 Training Loss: 0.3194, Training Accuracy: 95.6250%, Validation Loss: 5.2226, Validation Accuracy: 23.2143%\n",
      "Epoch 373/500 Training Loss: 0.3207, Training Accuracy: 95.4464%, Validation Loss: 5.2145, Validation Accuracy: 23.2143%\n",
      "Epoch 374/500 Training Loss: 0.3148, Training Accuracy: 95.7143%, Validation Loss: 5.2595, Validation Accuracy: 22.1429%\n",
      "Epoch 375/500 Training Loss: 0.3161, Training Accuracy: 94.9107%, Validation Loss: 5.2101, Validation Accuracy: 22.5000%\n",
      "Epoch 376/500 Training Loss: 0.3133, Training Accuracy: 95.2679%, Validation Loss: 5.2260, Validation Accuracy: 22.8571%\n",
      "Epoch 377/500 Training Loss: 0.3123, Training Accuracy: 95.1786%, Validation Loss: 5.2612, Validation Accuracy: 23.5714%\n",
      "Epoch 378/500 Training Loss: 0.3108, Training Accuracy: 95.4464%, Validation Loss: 5.2489, Validation Accuracy: 22.1429%\n",
      "Epoch 379/500 Training Loss: 0.3136, Training Accuracy: 95.1786%, Validation Loss: 5.2716, Validation Accuracy: 23.9286%\n",
      "Epoch 380/500 Training Loss: 0.3151, Training Accuracy: 95.2679%, Validation Loss: 5.2430, Validation Accuracy: 22.5000%\n",
      "Epoch 381/500 Training Loss: 0.3128, Training Accuracy: 94.8214%, Validation Loss: 5.2704, Validation Accuracy: 22.8571%\n",
      "Epoch 382/500 Training Loss: 0.3107, Training Accuracy: 95.4464%, Validation Loss: 5.2678, Validation Accuracy: 22.5000%\n",
      "Epoch 383/500 Training Loss: 0.3096, Training Accuracy: 95.4464%, Validation Loss: 5.2654, Validation Accuracy: 23.9286%\n",
      "Epoch 384/500 Training Loss: 0.3045, Training Accuracy: 95.8929%, Validation Loss: 5.3217, Validation Accuracy: 22.8571%\n",
      "Epoch 385/500 Training Loss: 0.3107, Training Accuracy: 95.2679%, Validation Loss: 5.3079, Validation Accuracy: 23.5714%\n",
      "Epoch 386/500 Training Loss: 0.3111, Training Accuracy: 95.4464%, Validation Loss: 5.2745, Validation Accuracy: 23.2143%\n",
      "Epoch 387/500 Training Loss: 0.3036, Training Accuracy: 95.7143%, Validation Loss: 5.2916, Validation Accuracy: 23.2143%\n",
      "Epoch 388/500 Training Loss: 0.3036, Training Accuracy: 95.9821%, Validation Loss: 5.3054, Validation Accuracy: 23.2143%\n",
      "Epoch 389/500 Training Loss: 0.3040, Training Accuracy: 95.3571%, Validation Loss: 5.3218, Validation Accuracy: 22.8571%\n",
      "Epoch 390/500 Training Loss: 0.3019, Training Accuracy: 95.3571%, Validation Loss: 5.3094, Validation Accuracy: 23.2143%\n",
      "Epoch 391/500 Training Loss: 0.3009, Training Accuracy: 95.6250%, Validation Loss: 5.3467, Validation Accuracy: 23.9286%\n",
      "Epoch 392/500 Training Loss: 0.3027, Training Accuracy: 95.4464%, Validation Loss: 5.3105, Validation Accuracy: 22.8571%\n",
      "Epoch 393/500 Training Loss: 0.2988, Training Accuracy: 95.8929%, Validation Loss: 5.3372, Validation Accuracy: 22.5000%\n",
      "Epoch 394/500 Training Loss: 0.2984, Training Accuracy: 95.8036%, Validation Loss: 5.3203, Validation Accuracy: 23.9286%\n",
      "Epoch 395/500 Training Loss: 0.2965, Training Accuracy: 95.5357%, Validation Loss: 5.3834, Validation Accuracy: 23.2143%\n",
      "Epoch 396/500 Training Loss: 0.2970, Training Accuracy: 95.9821%, Validation Loss: 5.3545, Validation Accuracy: 23.5714%\n",
      "Epoch 397/500 Training Loss: 0.2974, Training Accuracy: 95.6250%, Validation Loss: 5.3989, Validation Accuracy: 22.5000%\n",
      "Epoch 398/500 Training Loss: 0.2923, Training Accuracy: 96.0714%, Validation Loss: 5.3810, Validation Accuracy: 23.5714%\n",
      "Epoch 399/500 Training Loss: 0.2902, Training Accuracy: 95.8929%, Validation Loss: 5.3733, Validation Accuracy: 22.8571%\n",
      "Epoch 400/500 Training Loss: 0.2941, Training Accuracy: 95.5357%, Validation Loss: 5.3890, Validation Accuracy: 23.5714%\n",
      "Epoch 401/500 Training Loss: 0.2926, Training Accuracy: 96.0714%, Validation Loss: 5.4175, Validation Accuracy: 22.8571%\n",
      "Epoch 402/500 Training Loss: 0.2888, Training Accuracy: 95.9821%, Validation Loss: 5.3869, Validation Accuracy: 23.5714%\n",
      "Epoch 403/500 Training Loss: 0.2879, Training Accuracy: 95.7143%, Validation Loss: 5.4127, Validation Accuracy: 22.8571%\n",
      "Epoch 404/500 Training Loss: 0.2848, Training Accuracy: 96.6071%, Validation Loss: 5.4069, Validation Accuracy: 24.2857%\n",
      "Epoch 405/500 Training Loss: 0.2868, Training Accuracy: 95.9821%, Validation Loss: 5.3987, Validation Accuracy: 22.5000%\n",
      "Epoch 406/500 Training Loss: 0.2847, Training Accuracy: 96.8750%, Validation Loss: 5.4458, Validation Accuracy: 23.2143%\n",
      "Epoch 407/500 Training Loss: 0.2852, Training Accuracy: 96.1607%, Validation Loss: 5.4121, Validation Accuracy: 23.5714%\n",
      "Epoch 408/500 Training Loss: 0.2842, Training Accuracy: 96.4286%, Validation Loss: 5.4460, Validation Accuracy: 23.2143%\n",
      "Epoch 409/500 Training Loss: 0.2800, Training Accuracy: 95.8036%, Validation Loss: 5.4583, Validation Accuracy: 22.5000%\n",
      "Epoch 410/500 Training Loss: 0.2836, Training Accuracy: 96.5179%, Validation Loss: 5.4529, Validation Accuracy: 22.5000%\n",
      "Epoch 411/500 Training Loss: 0.2810, Training Accuracy: 95.6250%, Validation Loss: 5.4545, Validation Accuracy: 23.9286%\n",
      "Epoch 412/500 Training Loss: 0.2830, Training Accuracy: 96.6964%, Validation Loss: 5.4849, Validation Accuracy: 22.1429%\n",
      "Epoch 413/500 Training Loss: 0.2819, Training Accuracy: 96.0714%, Validation Loss: 5.4437, Validation Accuracy: 23.5714%\n",
      "Epoch 414/500 Training Loss: 0.2793, Training Accuracy: 96.3393%, Validation Loss: 5.4652, Validation Accuracy: 23.5714%\n",
      "Epoch 415/500 Training Loss: 0.2835, Training Accuracy: 95.5357%, Validation Loss: 5.5011, Validation Accuracy: 22.1429%\n",
      "Epoch 416/500 Training Loss: 0.2764, Training Accuracy: 96.9643%, Validation Loss: 5.5151, Validation Accuracy: 22.8571%\n",
      "Epoch 417/500 Training Loss: 0.2736, Training Accuracy: 96.3393%, Validation Loss: 5.4878, Validation Accuracy: 22.8571%\n",
      "Epoch 418/500 Training Loss: 0.2728, Training Accuracy: 96.8750%, Validation Loss: 5.5284, Validation Accuracy: 22.1429%\n",
      "Epoch 419/500 Training Loss: 0.2716, Training Accuracy: 96.6964%, Validation Loss: 5.4907, Validation Accuracy: 23.5714%\n",
      "Epoch 420/500 Training Loss: 0.2729, Training Accuracy: 96.3393%, Validation Loss: 5.5286, Validation Accuracy: 23.9286%\n",
      "Epoch 421/500 Training Loss: 0.2741, Training Accuracy: 96.6964%, Validation Loss: 5.5022, Validation Accuracy: 23.2143%\n",
      "Epoch 422/500 Training Loss: 0.2718, Training Accuracy: 96.6071%, Validation Loss: 5.4777, Validation Accuracy: 22.5000%\n",
      "Epoch 423/500 Training Loss: 0.2694, Training Accuracy: 96.3393%, Validation Loss: 5.5559, Validation Accuracy: 22.8571%\n",
      "Epoch 424/500 Training Loss: 0.2706, Training Accuracy: 96.0714%, Validation Loss: 5.5253, Validation Accuracy: 23.9286%\n",
      "Epoch 425/500 Training Loss: 0.2696, Training Accuracy: 96.6964%, Validation Loss: 5.5843, Validation Accuracy: 22.5000%\n",
      "Epoch 426/500 Training Loss: 0.2671, Training Accuracy: 97.0536%, Validation Loss: 5.5655, Validation Accuracy: 22.8571%\n",
      "Epoch 427/500 Training Loss: 0.2646, Training Accuracy: 96.8750%, Validation Loss: 5.5928, Validation Accuracy: 22.5000%\n",
      "Epoch 428/500 Training Loss: 0.2682, Training Accuracy: 96.4286%, Validation Loss: 5.5746, Validation Accuracy: 23.5714%\n",
      "Epoch 429/500 Training Loss: 0.2619, Training Accuracy: 97.2321%, Validation Loss: 5.5696, Validation Accuracy: 23.5714%\n",
      "Epoch 430/500 Training Loss: 0.2621, Training Accuracy: 96.5179%, Validation Loss: 5.5733, Validation Accuracy: 22.5000%\n",
      "Epoch 431/500 Training Loss: 0.2652, Training Accuracy: 96.4286%, Validation Loss: 5.5652, Validation Accuracy: 25.0000%\n",
      "Epoch 432/500 Training Loss: 0.2639, Training Accuracy: 96.8750%, Validation Loss: 5.6075, Validation Accuracy: 23.9286%\n",
      "Epoch 433/500 Training Loss: 0.2621, Training Accuracy: 96.7857%, Validation Loss: 5.5942, Validation Accuracy: 22.8571%\n",
      "Epoch 434/500 Training Loss: 0.2600, Training Accuracy: 96.6071%, Validation Loss: 5.6322, Validation Accuracy: 22.8571%\n",
      "Epoch 435/500 Training Loss: 0.2614, Training Accuracy: 97.1429%, Validation Loss: 5.6028, Validation Accuracy: 22.8571%\n",
      "Epoch 436/500 Training Loss: 0.2578, Training Accuracy: 96.9643%, Validation Loss: 5.6249, Validation Accuracy: 23.2143%\n",
      "Epoch 437/500 Training Loss: 0.2610, Training Accuracy: 96.9643%, Validation Loss: 5.6298, Validation Accuracy: 22.8571%\n",
      "Epoch 438/500 Training Loss: 0.2587, Training Accuracy: 97.3214%, Validation Loss: 5.6264, Validation Accuracy: 23.9286%\n",
      "Epoch 439/500 Training Loss: 0.2557, Training Accuracy: 97.3214%, Validation Loss: 5.6317, Validation Accuracy: 23.5714%\n",
      "Epoch 440/500 Training Loss: 0.2546, Training Accuracy: 96.7857%, Validation Loss: 5.6255, Validation Accuracy: 23.2143%\n",
      "Epoch 441/500 Training Loss: 0.2528, Training Accuracy: 97.3214%, Validation Loss: 5.6878, Validation Accuracy: 22.8571%\n",
      "Epoch 442/500 Training Loss: 0.2533, Training Accuracy: 96.8750%, Validation Loss: 5.6566, Validation Accuracy: 23.2143%\n",
      "Epoch 443/500 Training Loss: 0.2501, Training Accuracy: 97.2321%, Validation Loss: 5.6634, Validation Accuracy: 23.9286%\n",
      "Epoch 444/500 Training Loss: 0.2525, Training Accuracy: 97.3214%, Validation Loss: 5.6850, Validation Accuracy: 21.7857%\n",
      "Epoch 445/500 Training Loss: 0.2506, Training Accuracy: 97.4107%, Validation Loss: 5.7126, Validation Accuracy: 23.2143%\n",
      "Epoch 446/500 Training Loss: 0.2508, Training Accuracy: 97.5893%, Validation Loss: 5.7282, Validation Accuracy: 23.5714%\n",
      "Epoch 447/500 Training Loss: 0.2514, Training Accuracy: 97.5893%, Validation Loss: 5.6675, Validation Accuracy: 23.2143%\n",
      "Epoch 448/500 Training Loss: 0.2487, Training Accuracy: 97.3214%, Validation Loss: 5.7386, Validation Accuracy: 23.5714%\n",
      "Epoch 449/500 Training Loss: 0.2476, Training Accuracy: 97.0536%, Validation Loss: 5.7086, Validation Accuracy: 23.5714%\n",
      "Epoch 450/500 Training Loss: 0.2437, Training Accuracy: 97.8571%, Validation Loss: 5.7271, Validation Accuracy: 23.5714%\n",
      "Epoch 451/500 Training Loss: 0.2487, Training Accuracy: 96.8750%, Validation Loss: 5.6939, Validation Accuracy: 22.8571%\n",
      "Epoch 452/500 Training Loss: 0.2456, Training Accuracy: 97.4107%, Validation Loss: 5.7214, Validation Accuracy: 23.9286%\n",
      "Epoch 453/500 Training Loss: 0.2451, Training Accuracy: 97.8571%, Validation Loss: 5.7283, Validation Accuracy: 23.9286%\n",
      "Epoch 454/500 Training Loss: 0.2424, Training Accuracy: 97.1429%, Validation Loss: 5.7681, Validation Accuracy: 23.2143%\n",
      "Epoch 455/500 Training Loss: 0.2404, Training Accuracy: 97.7679%, Validation Loss: 5.7258, Validation Accuracy: 23.5714%\n",
      "Epoch 456/500 Training Loss: 0.2409, Training Accuracy: 97.2321%, Validation Loss: 5.7849, Validation Accuracy: 22.8571%\n",
      "Epoch 457/500 Training Loss: 0.2430, Training Accuracy: 97.5000%, Validation Loss: 5.7428, Validation Accuracy: 23.2143%\n",
      "Epoch 458/500 Training Loss: 0.2413, Training Accuracy: 97.9464%, Validation Loss: 5.7733, Validation Accuracy: 23.9286%\n",
      "Epoch 459/500 Training Loss: 0.2405, Training Accuracy: 97.3214%, Validation Loss: 5.7708, Validation Accuracy: 23.2143%\n",
      "Epoch 460/500 Training Loss: 0.2386, Training Accuracy: 97.5893%, Validation Loss: 5.7600, Validation Accuracy: 24.6429%\n",
      "Epoch 461/500 Training Loss: 0.2358, Training Accuracy: 97.9464%, Validation Loss: 5.7987, Validation Accuracy: 22.5000%\n",
      "Epoch 462/500 Training Loss: 0.2374, Training Accuracy: 97.5893%, Validation Loss: 5.7933, Validation Accuracy: 22.8571%\n",
      "Epoch 463/500 Training Loss: 0.2379, Training Accuracy: 97.1429%, Validation Loss: 5.8161, Validation Accuracy: 23.5714%\n",
      "Epoch 464/500 Training Loss: 0.2353, Training Accuracy: 97.3214%, Validation Loss: 5.8206, Validation Accuracy: 22.8571%\n",
      "Epoch 465/500 Training Loss: 0.2341, Training Accuracy: 97.5893%, Validation Loss: 5.8225, Validation Accuracy: 22.5000%\n",
      "Epoch 466/500 Training Loss: 0.2336, Training Accuracy: 97.8571%, Validation Loss: 5.8420, Validation Accuracy: 23.5714%\n",
      "Epoch 467/500 Training Loss: 0.2327, Training Accuracy: 98.1250%, Validation Loss: 5.8532, Validation Accuracy: 23.9286%\n",
      "Epoch 468/500 Training Loss: 0.2355, Training Accuracy: 97.5893%, Validation Loss: 5.8595, Validation Accuracy: 23.9286%\n",
      "Epoch 469/500 Training Loss: 0.2331, Training Accuracy: 97.5000%, Validation Loss: 5.8258, Validation Accuracy: 23.2143%\n",
      "Epoch 470/500 Training Loss: 0.2291, Training Accuracy: 98.1250%, Validation Loss: 5.8827, Validation Accuracy: 23.5714%\n",
      "Epoch 471/500 Training Loss: 0.2296, Training Accuracy: 98.1250%, Validation Loss: 5.8648, Validation Accuracy: 23.2143%\n",
      "Epoch 472/500 Training Loss: 0.2288, Training Accuracy: 97.8571%, Validation Loss: 5.8367, Validation Accuracy: 23.5714%\n",
      "Epoch 473/500 Training Loss: 0.2296, Training Accuracy: 98.1250%, Validation Loss: 5.9553, Validation Accuracy: 23.2143%\n",
      "Epoch 474/500 Training Loss: 0.2281, Training Accuracy: 97.9464%, Validation Loss: 5.8904, Validation Accuracy: 23.2143%\n",
      "Epoch 475/500 Training Loss: 0.2262, Training Accuracy: 98.0357%, Validation Loss: 5.9138, Validation Accuracy: 22.8571%\n",
      "Epoch 476/500 Training Loss: 0.2263, Training Accuracy: 97.5893%, Validation Loss: 5.9344, Validation Accuracy: 22.8571%\n",
      "Epoch 477/500 Training Loss: 0.2238, Training Accuracy: 98.2143%, Validation Loss: 5.9283, Validation Accuracy: 23.5714%\n",
      "Epoch 478/500 Training Loss: 0.2224, Training Accuracy: 98.2143%, Validation Loss: 5.9406, Validation Accuracy: 22.1429%\n",
      "Epoch 479/500 Training Loss: 0.2226, Training Accuracy: 97.9464%, Validation Loss: 5.9207, Validation Accuracy: 23.5714%\n",
      "Epoch 480/500 Training Loss: 0.2212, Training Accuracy: 98.2143%, Validation Loss: 5.9328, Validation Accuracy: 22.5000%\n",
      "Epoch 481/500 Training Loss: 0.2236, Training Accuracy: 98.0357%, Validation Loss: 5.9209, Validation Accuracy: 23.2143%\n",
      "Epoch 482/500 Training Loss: 0.2233, Training Accuracy: 98.5714%, Validation Loss: 5.9640, Validation Accuracy: 23.2143%\n",
      "Epoch 483/500 Training Loss: 0.2201, Training Accuracy: 98.1250%, Validation Loss: 5.9610, Validation Accuracy: 23.5714%\n",
      "Epoch 484/500 Training Loss: 0.2183, Training Accuracy: 98.4821%, Validation Loss: 5.9659, Validation Accuracy: 24.2857%\n",
      "Epoch 485/500 Training Loss: 0.2151, Training Accuracy: 98.5714%, Validation Loss: 5.9719, Validation Accuracy: 23.9286%\n",
      "Epoch 486/500 Training Loss: 0.2226, Training Accuracy: 97.7679%, Validation Loss: 5.9827, Validation Accuracy: 22.8571%\n",
      "Epoch 487/500 Training Loss: 0.2178, Training Accuracy: 98.2143%, Validation Loss: 5.9892, Validation Accuracy: 23.9286%\n",
      "Epoch 488/500 Training Loss: 0.2160, Training Accuracy: 98.1250%, Validation Loss: 6.0016, Validation Accuracy: 22.5000%\n",
      "Epoch 489/500 Training Loss: 0.2126, Training Accuracy: 98.8393%, Validation Loss: 6.0308, Validation Accuracy: 22.1429%\n",
      "Epoch 490/500 Training Loss: 0.2140, Training Accuracy: 98.5714%, Validation Loss: 6.0264, Validation Accuracy: 23.5714%\n",
      "Epoch 491/500 Training Loss: 0.2126, Training Accuracy: 98.6607%, Validation Loss: 6.0128, Validation Accuracy: 23.2143%\n",
      "Epoch 492/500 Training Loss: 0.2130, Training Accuracy: 98.3929%, Validation Loss: 6.0059, Validation Accuracy: 23.2143%\n",
      "Epoch 493/500 Training Loss: 0.2122, Training Accuracy: 98.2143%, Validation Loss: 6.0478, Validation Accuracy: 22.8571%\n",
      "Epoch 494/500 Training Loss: 0.2129, Training Accuracy: 98.3036%, Validation Loss: 6.0350, Validation Accuracy: 22.5000%\n",
      "Epoch 495/500 Training Loss: 0.2072, Training Accuracy: 98.5714%, Validation Loss: 6.0247, Validation Accuracy: 23.2143%\n",
      "Epoch 496/500 Training Loss: 0.2065, Training Accuracy: 98.4821%, Validation Loss: 6.0418, Validation Accuracy: 22.1429%\n",
      "Epoch 497/500 Training Loss: 0.2084, Training Accuracy: 98.5714%, Validation Loss: 6.0641, Validation Accuracy: 22.8571%\n",
      "Epoch 498/500 Training Loss: 0.2058, Training Accuracy: 98.6607%, Validation Loss: 6.0266, Validation Accuracy: 23.5714%\n",
      "Epoch 499/500 Training Loss: 0.2070, Training Accuracy: 98.2143%, Validation Loss: 6.1154, Validation Accuracy: 22.5000%\n",
      "Epoch 500/500 Training Loss: 0.2055, Training Accuracy: 98.2143%, Validation Loss: 6.0829, Validation Accuracy: 22.8571%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_correct_train = 0\n",
    "    total_samples_train = 0\n",
    "    total_loss_train = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        X_batch, y_batch = batch\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss_train = criterion(outputs, y_batch)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        total_loss_train += loss_train.item()\n",
    "\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_correct_train += (predicted == y_batch).sum().item()\n",
    "        total_samples_train += y_batch.size(0)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_correct_val = 0\n",
    "    total_samples_val = 0\n",
    "    total_loss_val = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            X_batch, y_batch = batch\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "            loss_val = criterion(outputs, y_batch)\n",
    "            total_loss_val += loss_val.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_correct += (predicted == y_batch).sum().item()\n",
    "            total_samples += y_batch.size(0)\n",
    "            total_correct_val += (predicted == y_batch).sum().item()\n",
    "            total_samples_val += y_batch.size(0)\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    avg_loss_train = total_loss_train / len(train_loader)\n",
    "    accuracy_train = total_correct_train / total_samples_train\n",
    "\n",
    "    avg_loss_val = total_loss_val / len(test_loader)\n",
    "    accuracy_val = total_correct_val / total_samples_val\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} Training Loss: {avg_loss_train:.4f}, Training Accuracy: {accuracy_train * 100:.4f}%, Validation Loss: {avg_loss_val:.4f}, Validation Accuracy: {accuracy_val * 100:.4f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'audio_classifier_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing New File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_audio_path = 'Recording.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Features of the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shami\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\audio.py:175: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "new_audio_feature = preprocess_audio_file(new_audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicts that the audio belongs to class: ['ac on']\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('audio_classifier_model.pth'))\n",
    "df = pd.read_csv('features.csv')\n",
    "\n",
    "new_audio_tensor = torch.tensor(new_audio_feature, dtype=torch.float32)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    new_audio_tensor = new_audio_tensor.unsqueeze(0)\n",
    "    predictions = model(new_audio_tensor)\n",
    "    _, predicted_class = torch.max(predictions, 1)\n",
    "\n",
    "# Convert the predicted class index back to the original label\n",
    "predicted_y = le.inverse_transform([predicted_class.item()])\n",
    "\n",
    "print(f\"The model predicts that the audio belongs to class: {predicted_y}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
